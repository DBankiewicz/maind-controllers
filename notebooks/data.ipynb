{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ead63bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOd: Tomasz Urban <tomasz.urban@alphacloud.com>\\nWysłano: 2025-04-03 09:18\\nDo: Katarzyna Pawlak <katarzyna.pawlak@szpilex.ai>\\nDW: Marek Jaworski <marek.jaworski@alphacloud.com>, support-leads@alphacloud.com\\nTemat: [Eskalacja] RAG Docs – błędne odpowiedzi i stara dokumentacja\\n\\nCześć Kasiu,\\n\\nmuszę podbić temat RAG-a, bo od wczoraj mamy kilka zgłoszeń od supportu:\\n\\n1) Case #SUP-23109:\\n   - pytanie agenta: “Czy klient na planie STANDARD ma dostęp do API /v3/billing/export?”\\n   - RAG odpowiedział: “Tak, endpoint dostępny od planu STANDARD wzwyż”.\\n   - Faktycznie: od stycznia endpoint jest tylko w ENTERPRISE (policy change).\\n\\n2) Case #SUP-23127:\\n   - pytanie o limit projektów w v3,\\n   - RAG zwrócił fragmenty dokumentacji z v2 (max 5 projektów), podczas gdy w v3 jest 20.\\n\\nWygląda na to, że:\\n- albo indeks zawiera stare wersje dokumentów,\\n- albo filtr po “version”/“valid_to” nie działa tak, jak zakładaliśmy.\\n\\nNa razie poprosiłem team leadów, żeby:\\n- traktowali odpowiedzi RAG-a jako “podpowiedź”, a nie źródło prawdy,\\n- w szczególności w tematach BILLING / LIMITY.\\n\\nCzy możesz dać znać:\\n- czy to jest pojedynczy bug, czy raczej systemowy problem z wersjonowaniem?\\n- oraz jaki widzisz realny horyzont na poprawkę?\\n\\nJeśli trzeba, podeślę konkretne query_id z rag_query_log.\\n\\nPozdrawiam,\\nTomek\\n\\n--\\nTomasz Urban\\nHead of Customer Support | AlphaCloud\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "# from data_loader.mail  import  Email\n",
    "mails = []\n",
    "DIR = \"/net/people/tutorial/tutorial014/wspole/data/mail-dataset\"\n",
    "for f  in os.listdir(DIR):\n",
    "    m = \"\".join(open(DIR+\"/\"+f, \"r\").readlines())\n",
    "    mails.append(m)\n",
    "    \n",
    "mails[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "376ac7fa-225e-495c-ae33-5fd1c1c1b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "\n",
    "class Email(BaseModel):\n",
    "    from_: str = Field(..., description=\"Sender email address\")\n",
    "    to: List[str] = Field(..., description=\"Recipient email addresses\")\n",
    "    topic: str = Field(..., description=\"Email topic or subject\")\n",
    "    data: str = Field(..., description=\"Full raw email content or body\")\n",
    "    summary: Optional[str] = Field(None, description=\"Auto-generated summary of the content\")\n",
    "    extra: dict[str, Any ]\n",
    "\n",
    "    class ConfigDict:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"from_\": \"alice@example.com\",\n",
    "                \"to\": [\"bob@example.com\"],\n",
    "                \"topic\": \"Meeting Update\",\n",
    "                \"data\": \"Hi Bob,\\nThe meeting is moved to Monday at 2 PM.\\nRegards,\\nAlice\",\n",
    "                \"summary\": \"Meeting rescheduled to Monday at 2 PM.\"\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c2ed3-53d4-46ba-8444-6abfa8ca0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "TOKEN = os.environ[\"CYFRANET_TOKEN\"]\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=TOKEN, \n",
    "    base_url=\"https://llmlab.plgrid.pl/api/v1\"\n",
    ")\n",
    "\n",
    "response =  client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "     messages=[{\"role\": \"user\", \"content\": f\"Wrtie mail addresses of recipents: {m}. Only output mail addreeses, no additional text\"}],\n",
    "    # input=f\"Znajdz tytul maila\" # {m}\"\n",
    ")\n",
    "    \n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c19fcf76-ca1a-4feb-977e-7058b557bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(client, model,  text): \n",
    "    response =  client.chat.completions.create(\n",
    "    model=model,\n",
    "     messages=[{\"role\": \"user\", \"content\": text}], # f\"Wrtie mail addresses of recipents: {m}. Only output mail addreeses, no additional text\"}],\n",
    "    # input=f\"Znajdz tytul maila\" # {m}\"\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def process_mail(mail: str, client: OpenAI) -> Email:\n",
    "    # from \n",
    "    from_ = extract_data(client, \"meta-llama/Llama-3.3-70B-Instruct\", f\"Wrtie mail addresses of sender: {mail}. This should be one email (usually after 'OD:'). Only output one mail address, no additional text\") \n",
    "    # to \n",
    "    to_ = extract_data(client, \"meta-llama/Llama-3.3-70B-Instruct\", f\"Wrtie mail addresses of recipents: {mail}. This should be at least one email (usually after 'DO:') at the top of the content.  Only output mail addreeses, no additional text\")\n",
    "    to_ = to_.split(\"\\n\")\n",
    "    # topic \n",
    "    topic = extract_data(client, \"meta-llama/Llama-3.3-70B-Instruct\", f\"Wrtie mail main topic: {mail}. This should be a field called 'Temat'. Only output mail title, no additional text\")\n",
    "    # data\n",
    "    data = mail \n",
    "    # summary \n",
    "    summary = extract_data(client, \"meta-llama/Llama-3.3-70B-Instruct\", f\"Summarize mail content in 3 sentences : {mail}. Only output summary, no additional text\")\n",
    "    # etra \n",
    "    tags = extract_data(client, \"meta-llama/Llama-3.3-70B-Instruct\", f\"Wrtie potential tags, categroies: {summary}. Only output categories separated by semicolon, no additional text\")\n",
    "\n",
    "    extra = {\"tags\": tags}\n",
    "    e = Email(from_=from_, to=to_, topic=topic, data=data, summary=summary, extra=extra)\n",
    "    return e\n",
    "    \n",
    "email = process_mail(mails[0], client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4858b4-c694-4a6f-8d0e-eea35f4468b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mails:\n",
    "    try:\n",
    "        email = process_mail(m, client)\n",
    "        print(email.topic)\n",
    "    except:\n",
    "        print(\"-----\")\n",
    "        print(m)\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
